# Arquivo: maintenance_ingestion_date.py
# Prop√≥sito: Adicionar coluna 'ingestion_date' retroativamente a todos os arquivos existentes

import boto3
import pandas as pd
import os
import logging
from datetime import datetime
from typing import List, Dict

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# --- CONFIGURA√á√ïES ---
TARGET_BUCKET = "20-ze-datalake-landing"
TARGET_PREFIX = "osrm_distance/osrm_landing/"
INGESTION_DATE = datetime.now().strftime('%Y-%m-%d')  # Data atual: 2025-11-27

# --- FUN√á√ïES AUXILIARES DE LIMPEZA ---

def cleanup_all_temp_files():
    """Remove TODOS os arquivos tempor√°rios do diret√≥rio atual (seguran√ßa)."""
    logging.warning("üö® Executando limpeza de emerg√™ncia de arquivos tempor√°rios...")
    removed = 0
    for f in os.listdir('.'):
        if f.startswith('temp_maintenance_') and f.endswith('.parquet'):
            try:
                os.remove(f)
                removed += 1
                logging.info(f"üóëÔ∏è  Removido: {f}")
            except Exception as e:
                logging.error(f"Erro ao remover {f}: {e}")
    logging.info(f"‚úÖ {removed} arquivo(s) tempor√°rio(s) removidos.")

# --- FUN√á√ïES ---

def list_all_parquet_files(bucket, prefix) -> List[Dict]:
    """Lista todos os arquivos .parquet recursivamente no prefixo alvo."""
    s3 = boto3.client('s3')
    files = []
    paginator = s3.get_paginator('list_objects_v2')
    
    logging.info(f"üîç Buscando arquivos em s3://{bucket}/{prefix}...")
    pages = paginator.paginate(Bucket=bucket, Prefix=prefix)
    
    for page in pages:
        if 'Contents' in page:
            for obj in page['Contents']:
                key = obj['Key']
                if key.endswith('.parquet'):
                    files.append({'Key': key, 'Size': obj['Size']})
    
    logging.info(f"‚úÖ {len(files)} arquivos .parquet encontrados para processamento.")
    return files

def process_and_overwrite(file_list: List[Dict], bucket: str, ingestion_date: str):
    """L√™, adiciona a coluna de data e reescreve o arquivo no S3."""
    s3 = boto3.client('s3')
    
    success_count = 0
    error_count = 0
    skipped_count = 0
    
    for idx, file_data in enumerate(file_list):
        s3_key = file_data['Key']
        
        # Nome local √∫nico para evitar conflitos
        local_path = f"temp_maintenance_{idx}.parquet"
        
        logging.info(f"[{idx+1}/{len(file_list)}] üìÇ Processando: {s3_key}")
        
        try:
            # 1. Download
            s3.download_file(bucket, s3_key, local_path)
            
            # 2. Leitura
            df = pd.read_parquet(local_path)
            
            # 3. Verificar se a coluna j√° existe
            if 'ingestion_date' in df.columns:
                logging.warning(f"‚ö†Ô∏è  [{idx+1}/{len(file_list)}] Coluna j√° existe. Pulando: {s3_key}")
                skipped_count += 1
                # LIMPEZA IMEDIATA se pular
                if os.path.exists(local_path):
                    os.remove(local_path)
                continue
            
            # 4. Adicionar coluna
            df['ingestion_date'] = ingestion_date
            
            # 5. Reescrever localmente
            df.to_parquet(local_path, index=False, engine='pyarrow')
            
            # 6. Upload (SOBRESCREVE o arquivo original)
            s3.upload_file(local_path, bucket, s3_key)
            
            # 7. LIMPEZA IMEDIATA ap√≥s upload bem-sucedido
            if os.path.exists(local_path):
                os.remove(local_path)
                logging.debug(f"üóëÔ∏è  Arquivo local deletado: {local_path}")
            
            success_count += 1
            logging.info(f"‚úÖ [{idx+1}/{len(file_list)}] Sucesso: {s3_key}")
            
        except Exception as e:
            error_count += 1
            logging.error(f"‚ùå [{idx+1}/{len(file_list)}] FALHA em {s3_key}: {e}")
            
        finally:
            # 8. GARANTIA FINAL: Limpeza no finally (dupla seguran√ßa)
            if os.path.exists(local_path):
                try:
                    os.remove(local_path)
                    logging.debug(f"üóëÔ∏è  [Finally] Arquivo local deletado: {local_path}")
                except Exception as cleanup_err:
                    logging.warning(f"‚ö†Ô∏è  Erro na limpeza final de {local_path}: {cleanup_err}")
        
        # Checkpoint a cada 50 arquivos + Verifica√ß√£o de espa√ßo
        if (idx + 1) % 50 == 0:
            logging.info(f"üìä Checkpoint: {success_count} sucessos | {skipped_count} pulados | {error_count} erros")
            
            # Verificar espa√ßo em disco
            import shutil
            disk = shutil.disk_usage('/')
            free_gb = disk.free / (1024**3)
            logging.info(f"üíæ Espa√ßo livre em disco: {free_gb:.1f}GB")
            
            if free_gb < 10:
                logging.error(f"‚ùå CR√çTICO: Apenas {free_gb:.1f}GB livres. Abortando para seguran√ßa.")
                # Limpeza de emerg√™ncia
                cleanup_all_temp_files()
                raise Exception("Espa√ßo em disco insuficiente")
    
    logging.info("="*60)
    logging.info(f"üìä RESUMO FINAL:")
    logging.info(f"   ‚úÖ Sucessos: {success_count}")
    logging.info(f"   ‚ö†Ô∏è  Pulados: {skipped_count}")
    logging.info(f"   ‚ùå Erros: {error_count}")
    logging.info("="*60)

if __name__ == "__main__":
    logging.info("="*60)
    logging.info(f"üõ†Ô∏è  Manuten√ß√£o Retroativa: Ingestion Date")
    logging.info(f"üìÖ Data de Ingest√£o: {INGESTION_DATE}")
    logging.info(f"üéØ Bucket: {TARGET_BUCKET}")
    logging.info(f"üìÅ Prefixo: {TARGET_PREFIX}")
    logging.info("="*60)
    
    # 0. LIMPEZA PREVENTIVA: Remove qualquer arquivo tempor√°rio antigo
    cleanup_all_temp_files()
    
    # 1. Listar todos os arquivos
    all_files = list_all_parquet_files(TARGET_BUCKET, TARGET_PREFIX)
    
    if not all_files:
        logging.warning("‚ö†Ô∏è  Nenhum arquivo encontrado. Finalizando.")
        exit(0)
    
    # 2. Confirma√ß√£o de seguran√ßa
    print(f"\n‚ö†Ô∏è  ATEN√á√ÉO: {len(all_files)} arquivos ser√£o MODIFICADOS e SOBRESCRITOS!")
    print(f"üìÖ Coluna 'ingestion_date' ser√° adicionada com valor: {INGESTION_DATE}")
    print("\nüîí Esta opera√ß√£o √© IRREVERS√çVEL sem backup!")
    confirm = input("\nDigite 'CONFIRMAR' para prosseguir (ou Enter para cancelar): ")
    
    if confirm != "CONFIRMAR":
        logging.info("‚ùå Opera√ß√£o cancelada pelo usu√°rio.")
        exit(0)
    
    # 3. Processar e sobrescrever
    logging.info("üöÄ Iniciando processamento...")
    try:
        process_and_overwrite(all_files, TARGET_BUCKET, INGESTION_DATE)
    except Exception as e:
        logging.error(f"‚ùå Erro durante processamento: {e}")
        cleanup_all_temp_files()  # Limpeza de emerg√™ncia
        exit(1)
    finally:
        # 4. LIMPEZA FINAL GARANTIDA (mesmo se houver erro)
        cleanup_all_temp_files()
    
    logging.info("="*60)
    logging.info("üéâ Manuten√ß√£o Retroativa CONCLU√çDA")
    logging.info("="*60)